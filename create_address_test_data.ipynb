{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb48701-8d9c-465c-b179-6c0b7fcf3ac2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up reusable functions"
    }
   },
   "outputs": [],
   "source": [
    "def dirty_address_data(address_row):\n",
    "    \"\"\"\n",
    "        Return a dict row with dirtied address data.\n",
    "        Accepts: address_row (py dict)\n",
    "        Returns dirtied address_row (py_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    postcode_mods = [\n",
    "        lambda x: x.replace(\"9\",\"E\"),\n",
    "        lambda x: x.replace(\"E\",\"9\"),\n",
    "        lambda x: x.replace(\"0\",\"o\"),\n",
    "        lambda x: x.replace(\"o\",\"0\"),\n",
    "        lambda x: x.replace(\"1\",\"l\"),\n",
    "        lambda x: x.replace(\"l\",\"1\"),\n",
    "    ]\n",
    "    mods = [\n",
    "        lambda x: x.replace(\"Street\", \"St\"),                           # abbreviate\n",
    "        lambda x: x.replace(\"Road\", \"Rd\"),                             # abbreviate\n",
    "        lambda x: x.replace(\"Road\", \"\"),                               # drop words\n",
    "        lambda x: x.replace(\"Street\", \"\"),                             # drop words\n",
    "        lambda x: x.replace(\"o\", \"0\"),                                 # typo\n",
    "        lambda x: x.replace(\"1\",\"l\"),                                  # typo\n",
    "        lambda x: x.replace(\"l\",\"1\"),                                  # typo\n",
    "        lambda x: x.upper(),                                           # all caps\n",
    "        lambda x: x.lower(),                                           # all lowercase\n",
    "        lambda x: x + \" Apt 1B\",                                       # add noise\n",
    "        lambda x: x[:len(x)//2],                                       # truncate\n",
    "    ]\n",
    "    \n",
    "    address_row[\"postcode\"] = random.choice(postcode_mods)(address_row[\"postcode\"])\n",
    "    address_row[\"fulladdress\"] = random.choice(mods)(address_row[\"fulladdress\"])\n",
    "    return address_row\n",
    "\n",
    "def destroy_address_data(address_row):\n",
    "    \"\"\"\n",
    "        Return a dict with destroyed address data.\n",
    "        Accepts: address_row (py dict)\n",
    "        Returns destroyed address_row (py_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    postcode_mods = [\n",
    "        lambda x: \"\",\n",
    "        lambda x: \"NOTAPOSTC\"\n",
    "    ]\n",
    "    mods = [\n",
    "        lambda x: \"123 Madeup Road, Imaginary Town\",                   # fully fake\n",
    "        lambda x: \"\",                                                  # blank out\n",
    "        lambda x: x[::-1],                                             # reverse string\n",
    "    ]\n",
    "\n",
    "    # dirty postcode\n",
    "    address_row[\"postcode\"] = random.choice(postcode_mods)(address_row[\"postcode\"])\n",
    "    # address line\n",
    "    address_row[\"fulladdress\"] = random.choice(mods)(address_row[\"fulladdress\"])\n",
    "    address_row[\"expected_uprn\"] = None\n",
    "    return address_row\n",
    "    \n",
    "def transform_row(row):\n",
    "    row_dict = row.asDict()\n",
    "\n",
    "    if row_dict[\"unique_id\"] % 2 == 0:\n",
    "        return dirty_address_data(row_dict)\n",
    "    elif row_dict[\"unique_id\"] % 7 == 0:\n",
    "        return destroy_address_data(row_dict)\n",
    "    else:\n",
    "        return row_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b873fa4-e704-439e-895b-bc853f277b0a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get all canonical address data"
    }
   },
   "outputs": [],
   "source": [
    "# Get all addresses (currently a subset of GB addresses)\n",
    "all_address_sdf = spark.read.option(\"header\", True).csv([\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_0.csv\",\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_1.csv\",\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_2.csv\",\n",
    "    \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_3.csv\",\n",
    "])\n",
    "\n",
    "# Extract required fields for address matching\n",
    "all_address_sdf = all_address_sdf.select(\n",
    "    \"uprn\",\n",
    "    \"fulladdress\",\n",
    "    \"postcode\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b676a51a-c273-4fcb-aefa-6dd3ff5decad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create generic test sample data"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "import random\n",
    "\n",
    "number_of_test_rows = 50\n",
    "\n",
    "# Generate SAMPLE of addresses to dirty\n",
    "address_samples = all_address_sdf.orderBy(F.rand()).limit(number_of_test_rows)\n",
    "address_samples = address_samples.withColumnRenamed(\"uprn\", \"expected_uprn\")\n",
    "# give each test address a key of 'unique_id' to join-on in matcher output\n",
    "address_samples = address_samples.withColumn(\"unique_id\", F.monotonically_increasing_id())\n",
    "    \n",
    "address_samples = address_samples.rdd.map(transform_row).toDF()\n",
    "# we dont want uprn potenitally interfearing with matching\n",
    "input_address_samples = address_samples.drop(\"expected_uprn\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9208a8-7920-4fe2-82d1-779c29342413",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MoJ algorithm inputs"
    }
   },
   "outputs": [],
   "source": [
    "# change column names to match moj address matcher's expectations\n",
    "\n",
    "moj_input_address_samples = input_address_samples.withColumnRenamed(\"fulladdress\", \"address_concat\")\n",
    "\n",
    "moj_all_address_subset_sdf = all_address_sdf.withColumnRenamed(\"uprn\", \"unique_id\").withColumnRenamed(\"fulladdress\", \"address_concat\")\n",
    "\n",
    "# MoJ algo wants to read from a Parquet file format\n",
    "moj_input_address_samples.write.mode(\"overwrite\").parquet(\"dbfs:/tmp/address_data/input/\")\n",
    "moj_all_address_subset_sdf.write.mode(\"overwrite\").parquet(\"dbfs:/tmp/address_data/all\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_address_test_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
