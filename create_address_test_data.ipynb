{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Databricks Connect\n",
      "Spark Version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "%run ./local_dev/spark_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb48701-8d9c-465c-b179-6c0b7fcf3ac2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up reusable functions"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "DESTROY_MODULO = 7\n",
    "DIRTY_MODULO = 2\n",
    "\n",
    "dirty_postcode_mods = [\n",
    "    lambda x: x.replace(\"9\", \"E\"),\n",
    "    lambda x: x.replace(\"E\", \"9\"),\n",
    "    lambda x: x.replace(\"0\", \"o\"),\n",
    "    lambda x: x.replace(\"o\", \"0\"),\n",
    "    lambda x: x.replace(\"1\", \"l\"),\n",
    "    lambda x: x.replace(\"l\", \"1\"),\n",
    "    lambda x: x.replace(\"I\", \"1\"),\n",
    "    lambda x: x.replace(\"B\", \"8\"),\n",
    "    lambda x: x.replace(\"S\", \"5\"),\n",
    "    lambda x: x.replace(\"G\", \"6\"),\n",
    "    lambda x: x.replace(\"Z\", \"2\"),\n",
    "    lambda x: x.replace(\"C\", \"0\"),\n",
    "    lambda x: x.replace(\"K\", \"X\"),\n",
    "    lambda x: x.lower(),\n",
    "    lambda x: x.upper(),\n",
    "    lambda x: x.replace(\" \", \"\"),\n",
    "    lambda x: x[:len(x)//2],\n",
    "    lambda x: x + \"X\",\n",
    "    lambda x: x + \"'\",\n",
    "    lambda x: x + \".\",\n",
    "    lambda x: x + \",\",\n",
    "    lambda x: \"X\" + x,\n",
    "    lambda x: \"]\" + x,\n",
    "    lambda x: x[:-1] + \"Z\" if len(x) > 1 else x,\n",
    "    lambda x: x[1:] if len(x) > 1 else x,\n",
    "    lambda x: x[:-1] if len(x) > 1 else x,\n",
    "    lambda x: x + \" \" + x[-1],\n",
    "    lambda x: x[:2] + \" \" + x[2:] if len(x) > 2 else x,\n",
    "    lambda x: x.replace(\" \", \"  \"),\n",
    "    lambda x: x[::-1],\n",
    "]\n",
    "\n",
    "destroy_postcode_mods = [\n",
    "    lambda x: \"\",\n",
    "    lambda x: \"NOTAPOSTC\",\n",
    "]\n",
    "\n",
    "dirty_address_mods = [\n",
    "    lambda x: x.replace(\"Street\", \"St\"),\n",
    "    lambda x: x.replace(\"Road\", \"Rd\"),\n",
    "    lambda x: x.replace(\"Road\", \"\"),\n",
    "    lambda x: x.replace(\"Street\", \"\"),\n",
    "    lambda x: x.replace(\"o\", \"0\"),\n",
    "    lambda x: x.replace(\"1\", \"l\"),\n",
    "    lambda x: x.replace(\"l\", \"1\"),\n",
    "    lambda x: x.upper(),\n",
    "    lambda x: x.lower(),\n",
    "    lambda x: x + \" Apt 1B\",\n",
    "    lambda x: x[:len(x)//2],\n",
    "    lambda x: x.replace(\"Avenue\", \"Ave\"),\n",
    "    lambda x: x.replace(\"Ave\", \"\"),\n",
    "    lambda x: x.replace(\"Apartment\", \"Apt\"),\n",
    "    lambda x: x.replace(\"Building\", \"Bldg\"),\n",
    "    lambda x: x.replace(\",\", \"\"),\n",
    "    lambda x: x + \", United Kingdom\",\n",
    "    lambda x: x + \", UK\",\n",
    "    lambda x: \"Flat \" + x,\n",
    "    lambda x: x.replace(\" \", \"\"),\n",
    "    lambda x: \" \".join(x.split()[:-1]),\n",
    "    lambda x: \" \".join(x.split()[1:]),\n",
    "    lambda x: x + \" London\",\n",
    "    lambda x: x.replace(\"London\", \"Londom\"),\n",
    "    lambda x: x.replace(\"Main\", \"Mian\"),\n",
    "    lambda x: x.replace(\"o\", \"\"),\n",
    "    lambda x: x.replace(\"a\", \"@\"),\n",
    "    lambda x: x.replace(\"e\", \"3\"),\n",
    "    lambda x: x.replace(\"s\", \"$\"),\n",
    "    lambda x: x.title(),\n",
    "    lambda x: \" \".join(list(x)),\n",
    "]\n",
    "\n",
    "destroy_address_mods = [\n",
    "    lambda x: \"123 Madeup Road, Imaginary Town\",\n",
    "    lambda x: \"\",\n",
    "    lambda x: x[::-1],\n",
    "]\n",
    "\n",
    "def transform_postcode(unique_id, postcode):\n",
    "    if unique_id % DESTROY_MODULO == 0:\n",
    "        return random.choice(destroy_postcode_mods)(postcode)\n",
    "    elif unique_id % DIRTY_MODULO == 0:\n",
    "        return random.choice(dirty_postcode_mods)(postcode)\n",
    "    else:\n",
    "        return postcode\n",
    "\n",
    "def transform_fulladdress(unique_id, fulladdress):\n",
    "    if unique_id % DESTROY_MODULO == 0:\n",
    "        return random.choice(destroy_address_mods)(fulladdress)\n",
    "    elif unique_id % DIRTY_MODULO == 0:\n",
    "        return random.choice(dirty_address_mods)(fulladdress)\n",
    "    else:\n",
    "        return fulladdress\n",
    "\n",
    "def transform_expected_uprn(unique_id, current_uprn):\n",
    "    if unique_id % DESTROY_MODULO == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return current_uprn\n",
    "    \n",
    "transform_postcode_udf = udf(transform_postcode, StringType())\n",
    "transform_fulladdress_udf = udf(transform_fulladdress, StringType())\n",
    "transform_expected_uprn_udf = udf(transform_expected_uprn, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b873fa4-e704-439e-895b-bc853f277b0a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get all canonical address data"
    }
   },
   "outputs": [],
   "source": [
    "# Get all GB addresses\n",
    "all_address_sdf = spark.read.option(\"header\", True).csv([\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_0.csv\",\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_1.csv\",\n",
    "    # \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_2.csv\",\n",
    "    \"dbfs:/Volumes/catalog-sbx-uks-ctdp-001/schema-sbx-uks-ctdp-001-acquire-clickops/test_ctdp/part_3.csv\",\n",
    "])\n",
    "\n",
    "# Extract required fields for address matching\n",
    "all_address_sdf = all_address_sdf.select(\n",
    "    \"uprn\",\n",
    "    \"fulladdress\",\n",
    "    \"postcode\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b676a51a-c273-4fcb-aefa-6dd3ff5decad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create generic test sample data"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test data rows: 50\n",
      "+-------------+-----------------------------------------------+---------+---------+\n",
      "|expected_uprn|fulladdress                                    |postcode |unique_id|\n",
      "+-------------+-----------------------------------------------+---------+---------+\n",
      "|NULL         |                                               |         |0        |\n",
      "|100020439557 |83A, MARLOW ROAD, PENGE, LONDON, SE20 7XR      |SE20 7XR |1        |\n",
      "|100031672960 |326 TUTBURY ROAD BURTON UPON TRENT DE13 0AJ    |E13 0AJ  |2        |\n",
      "|32026746     |13, CHESTNUT AVENUE, TIPTON, DY4 9QT           |DY4 9QT  |3        |\n",
      "|100022274445 |220, ST BARNABAS ROAD, WOODFORD GREEN, IG8 7DR |IG8 7DR  |4        |\n",
      "|100022296699 |23, PALEWELL PARK, EAST SHEEN, LONDON, SW14 8JQ|SW14 8JQ |5        |\n",
      "|100022572263 |40, NEVILLE CLOSE, LEYTONSTONE, E11 3QH        |911 3QH  |6        |\n",
      "|NULL         |                                               |NOTAPOSTC|7        |\n",
      "|100020262517 |27, THE GROVE, SIDCUP, DA14 5NG                |DA14  5NG|8        |\n",
      "|100022190010 |42, MANFORD CROSS, CHIGWELL, IG7 4AB           |IG7 4AB  |9        |\n",
      "+-------------+-----------------------------------------------+---------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "number_of_test_rows = 50\n",
    "\n",
    "# Generate SAMPLE of addresses to dirty\n",
    "address_samples = all_address_sdf.orderBy(F.rand()).limit(number_of_test_rows)\n",
    "address_samples = address_samples.withColumnRenamed(\"uprn\", \"expected_uprn\")\n",
    "# give each test address a key of 'unique_id' to join-on in matcher output (UPRNs want be present in all matcher output)\n",
    "address_samples = address_samples.withColumn(\"unique_id\", F.monotonically_increasing_id())\n",
    "\n",
    "address_samples = address_samples \\\n",
    "    .withColumn(\"postcode\", transform_postcode_udf(\"unique_id\", \"postcode\")) \\\n",
    "    .withColumn(\"fulladdress\", transform_fulladdress_udf(\"unique_id\", \"fulladdress\")) \\\n",
    "    .withColumn(\"expected_uprn\", transform_expected_uprn_udf(\"unique_id\", \"expected_uprn\"))\n",
    "\n",
    "count = address_samples.count()\n",
    "print(f\"Number of test data rows: {count}\")\n",
    "address_samples.show(10, truncate=False)\n",
    "# we dont want uprn potentially interfering with matching\n",
    "input_address_samples = address_samples.drop(\"expected_uprn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9208a8-7920-4fe2-82d1-779c29342413",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MoJ algorithm inputs"
    }
   },
   "outputs": [],
   "source": [
    "# # change column names to match moj address matcher's expectations\n",
    "moj_input_address_samples = input_address_samples.withColumnRenamed(\"fulladdress\", \"address_concat\")\n",
    "moj_all_address_subset_sdf = all_address_sdf.withColumnRenamed(\"uprn\", \"unique_id\").withColumnRenamed(\"fulladdress\", \"address_concat\")\n",
    "\n",
    "# MoJ algo wants to read from a Parquet file format\n",
    "moj_input_address_samples.write.mode(\"overwrite\").parquet(\"dbfs:/tmp/address_data/input/\")\n",
    "moj_all_address_subset_sdf.write.mode(\"overwrite\").parquet(\"dbfs:/tmp/address_data/all\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_address_test_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv_db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
