# The main job for deploy_infra.
resources:
  jobs:
    london_pollutant_data_pipeline:
      name: London Pollutant Data Pipeline
      schedule:
        quartz_cron_expression: "0 0 14-17 ? * *"  # min 0 of 14,15,16,17 hours daily
        timezone_id: "UTC"
        pause_status: "UNPAUSED"
      tasks:
        - task_key: run_la_prerequisite
          existing_cluster_id: ${var.shared_cluster_id}
          spark_python_task:
            python_file: "/Workspace/Users/${var.spn_id}/.bundle/${bundle.name}/files/src/test_one.py"

        - task_key: injest_london_authority_pollutant_data
          existing_cluster_id: ${var.shared_cluster_id}
          description: Run the consume environmental data notebook
          notebook_task:
            notebook_path: "/Workspace/Users/${var.spn_id}/.bundle/${bundle.name}/files/src/bronze"

        - task_key: process_london_authority_pollutant_data
          depends_on:
            - task_key: injest_london_authority_pollutant_data
            - task_key: run_la_prerequisite
          existing_cluster_id: ${var.shared_cluster_id}
          description: Run the consume environmental data notebook
          notebook_task:
            notebook_path: "/Workspace/Users/${var.spn_id}/.bundle/${bundle.name}/files/src/silver"

        - task_key: generate_london_pollutant_data_analysis
          depends_on:
            - task_key: process_london_authority_pollutant_data
          existing_cluster_id: ${var.shared_cluster_id}
          description: Run the consume environmental data notebook
          notebook_task:
            notebook_path: "/Workspace/Users/${var.spn_id}/.bundle/${bundle.name}/files/src/gold"

        - task_key: produce_la_output_files
          depends_on:
            - task_key: process_london_authority_pollutant_data
          existing_cluster_id: ${var.shared_cluster_id}
          spark_python_task:
            python_file: "/Workspace/Users/${var.spn_id}/.bundle/${bundle.name}/files/src/test_two.py"

