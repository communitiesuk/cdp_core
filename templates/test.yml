parameters:
  - name: environment
    type: string

stages:
  - stage: TEST
    displayName: "TEST"
    dependsOn: DEV
    condition: succeeded('DEV')
    jobs:
      - job: TEST
        # pool: 
        #   name: 'vmss-shared'
        displayName: "Deploy Test"
        variables:
        - template: variables.yml
          parameters:
            environment: ${{ parameters.environment }}

        steps:
          # 1. Install All Requirements
          - script: |
              echo $(DATABRICKS_HOST)
              curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
            displayName: "Install Databricks CLI"

          # 2. Set Environment Variables & Allow Executables
          - script: |
              set -e
              export DATABRICKS_HOST=$(DATABRICKS_HOST)
              export ENVIRONMENT=$(ENVIRONMENT)
              chmod +x ./templates/scripts/bump-version.sh
            displayName: "Setting Environment Variables & Allowing Executables"

          # 3. Get and Increment Tag
          - script: templates/scripts/bump-version.sh
            displayName: "Get and Increment Tag"

          # 4. Validate Databricks Bundle
          - template: steps/test_azure_cli.yml
            parameters:
              description: "Validating Databricks Bundle"
              inlineScript: |
                databricks bundle validate --var="environment=$(ENVIRONMENT),whl_path=/Workspace/Shared/artifacts/cdp_core-$(BUILD_VERSION)-py3-none-any.whl"
          
          # 5. Deploy Databricks Bundle
          - template: steps/test_azure_cli.yml
            parameters:
              description: "Deploy Databricks Bundle"
              inlineScript: |
                databricks bundle deploy --var="environment=$(ENVIRONMENT),whl_path=/Workspace/Shared/artifacts/cdp_core-$(BUILD_VERSION)-py3-none-any.whl"

          # 6. Run System Integration Tests
          - template: steps/test_azure_cli.yml
            parameters:
              description: "Run System Integration Tests"
              inlineScript: |
                ls resources/*.yml | xargs -n 1 basename | sed 's/\.yml$//' > bundle_names.txt
                declare -a pids
                declare -a statuses
                
                for bundle_name in $(cat bundle_names.txt); do
                  clean_name="${bundle_name%.job}"
                  if [[ "$clean_name" == *pytest* ]]; then
                    echo "Skipping bundle: $clean_name (contains 'pytest')"
                    continue
                  fi
                  echo "Running bundle: $clean_name"
                  databricks bundle run "$clean_name" --refresh-all --var="environment=$(ENVIRONMENT),whl_path=/Workspace/Shared/artifacts/cdp_core-$(BUILD_VERSION)-py3-none-any.whl"&
                  pids+=($!)
                done

                # Wait for all jobs and collect exit codes
                for pid in "${pids[@]}"; do
                  wait $pid
                  statuses+=($?)
                done

                # Check if any job failed
                for status in "${statuses[@]}"; do
                  if [[ $status -ne 0 ]]; then
                    echo "One or more bundle runs failed."
                    exit 1
                  fi
                done